{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################<br>\n",
    "File: Getting Started with PySpark <br>\n",
    "Desc: Introduction to PySpark<br>\n",
    "Auth: Shreenidhi Bharadwaj<br>\n",
    "Date: 9/29/2019<br>\n",
    "ALL RIGHTS RESERVED | DO NOT DISTRIBUTE<br>\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ignore warnings for now\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/sbharadwaj/opt/anaconda3/lib/python3.7/site-packages (2.4.4)\r\n",
      "Requirement already satisfied: py4j==0.10.7 in /Users/sbharadwaj/opt/anaconda3/lib/python3.7/site-packages (from pyspark) (0.10.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Context\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create an RDD\n",
    "data = sc.parallelize([1,2,3,3])\n",
    "data.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 27, 27]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us use a map transformation - use lambda function to return the cube of each element\n",
    "data.map(lambda x: x * x * x).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.4142135623730951, 1.7320508075688772, 1.7320508075688772]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a function instead of a lambda function - we will get the square root of each element\n",
    "import math\n",
    "def convert(x):\n",
    "    return math.sqrt(x)\n",
    "data.map(convert).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use filter to get only odd numbers\n",
    "data.filter(lambda x: x % 2 != 0).take(4) #there will be just 3 odd elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us remove duplicates\n",
    "data.distinct().take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us take a sample - note you may not get the same answer\n",
    "data.sample(False, 0.2).take(4) #False implies no replacement; 0.2 is the probability of each element being chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 3, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#let us try a few set-like RDD operations\n",
    "rdd1 = sc.parallelize([1,2,3,4,5])\n",
    "rdd2 = sc.parallelize([3,5,6,7,8])\n",
    "\n",
    "#union\n",
    "rdd1.union(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intersection\n",
    "rdd1.intersection(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtract\n",
    "rdd1.subtract(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (1, 8),\n",
       " (2, 3),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (3, 3),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (3, 7),\n",
       " (3, 8),\n",
       " (4, 3),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (4, 7),\n",
       " (4, 8),\n",
       " (5, 3),\n",
       " (5, 5),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (5, 8)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cartesian product\n",
    "rdd1.cartesian(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us look at some actions\n",
    "rdd1.collect() #returns all the elements from the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of elements in the RDD\n",
    "rdd1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 1, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us create a union and check to see how many times each element occurs in the RDD\n",
    "u = rdd1.union(rdd2)\n",
    "u.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return the first element\n",
    "u.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return the first 3 elements\n",
    "u.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 7, 6]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return the top n elements\n",
    "u.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "#rdd1 is [1,2,3,4,5]. Let us get the product of the elements\n",
    "product = rdd1.reduce(lambda x, y: x * y)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mon', 600.25), ('Tue', 1215.5), ('Wed', 100.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us try a few transformations on paired RDDs\n",
    "#assume that we have multiple sales values per day....not all days of the week are shown\n",
    "paired_RDD = sc.parallelize([(\"Mon\", 200.00), (\"Tue\", 1215.50), (\"Mon\", 300.25),(\"Wed\", 100.00),(\"Mon\", 100.00)])\n",
    "#get total sales by day\n",
    "sales_by_day = paired_RDD.reduceByKey(lambda x, y: x + y)\n",
    "sales_by_day.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mon', <pyspark.resultiterable.ResultIterable at 0x1122fffd0>),\n",
       " ('Tue', <pyspark.resultiterable.ResultIterable at 0x1122ff350>),\n",
       " ('Wed', <pyspark.resultiterable.ResultIterable at 0x1122ff0d0>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us group by key - get key and an iterable of items\n",
    "grouped_RDD = paired_RDD.groupByKey()\n",
    "grouped_RDD.collect() #note that the value will be an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mon', [200.0, 300.25, 100.0]), ('Tue', [1215.5]), ('Wed', [100.0])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us get a list instead of an iterator ...\n",
    "list_RDD = paired_RDD.groupByKey().mapValues(list)\n",
    "list_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mon', 200.0),\n",
       " ('Mon', 300.25),\n",
       " ('Mon', 100.0),\n",
       " ('Tue', 1215.5),\n",
       " ('Wed', 100.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us convert list_RDD back to the paired RDD that we started with\n",
    "original_RDD = list_RDD.flatMapValues(lambda x: x)\n",
    "original_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wed', 100.0),\n",
       " ('Tue', 1215.5),\n",
       " ('Mon', 200.0),\n",
       " ('Mon', 300.25),\n",
       " ('Mon', 100.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us sort out original RDD by key in descending order\n",
    "sorted_RDD = original_RDD.sortByKey(ascending = False) #default is in ascending order\n",
    "sorted_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mon', 100.0),\n",
       " ('Wed', 100.0),\n",
       " ('Mon', 200.0),\n",
       " ('Mon', 300.25),\n",
       " ('Tue', 1215.5)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us sort by value\n",
    "sort_by_value = original_RDD.sortBy(lambda pair: pair[1], True) # use - False to sort in descending order\n",
    "sort_by_value.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"fixed acidity\";\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"',\n",
       " '7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6',\n",
       " '6.3;0.3;0.34;1.6;0.049;14;132;0.994;3.3;0.49;9.5;6']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    aList = line.split(\";\")\n",
    "    features = [float(x) for x in aList[:-1]]\n",
    "    label = labels[aList[-1]]\n",
    "    \n",
    "    return LabeledPoint(label, features)\n",
    "\n",
    "data = sc.textFile(\"../data/winequality-white.csv\")\n",
    "data.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
